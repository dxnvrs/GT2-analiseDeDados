Usaremos determinadas ferramentas para o início da coleta de dados. Primeiro é preciso estabelecer o ambiente de programação. Existem várias IDEs (Ambientes de Desenvolvimento Integrado) especializadas em coleta e análise de dados – como Spyder, Jupyter Notebook e DataSpell –, mas usaremos um editor de código que mistura praticidade e vários recursos importantes com certa facilidade de uso, o Visual Studio. Além disso, Python possui muitas bibliotecas que facilitam o processo de raspagem de dados de sites (processo automático que visa coletar materiais específicos de páginas web, como por exemplo a quantidade de ocorrências de alguma enfermidade) e organização deles.   
